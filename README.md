# Introduction
MLT \_\_init\_\_ is a monthly event led by [Jayson Cunanan](https://www.linkedin.com/in/jayson-cunanan-phd/) and [J. Miguel Valverde](https://twitter.com/jmlipman) where, similarly to a traditional journal club, a paper is first presented by a volunteer and then discussed among all attendees. Our goal is to give participants good **initializations** to effectively study and improve their understanding of Deep Learning. We will try to achieve this by:
* Discussing **fundamental papers**, whose main ideas are currently implemented on state-of-the-art models.
* Providing the audience with summaries, codes and visualizations to help understand the critical parts of a paper.

# Sessions
| Date        | Topic                           | Paper                  | Presenter         | Video |
|-------------|---------------------------------|------------------------|--------------------|---------------------|
| 10/Jan/2021 | CV: Separable Convolutions      | [Xception](https://arxiv.org/abs/1610.02357)               | [Jayson Cunanan](https://www.linkedin.com/in/jayson-cunanan-phd/)     |  ![Youtube](https://www.shareicon.net/data/32x32/2016/07/09/118264_youtube_512x512.png) |
| 14/Feb/2021 | CV: Dilated Convolutions + ASPP | [DeepLabv2](https://arxiv.org/abs/1606.00915)              | [J. Miguel Valverde](https://www.twitter.com/jmlipman)    |  ![Youtube](https://www.shareicon.net/data/32x32/2016/07/09/118264_youtube_512x512.png) |
| 14/Mar/2021 | CV: Attention in Images         | [Squeeze and Excitation](https://arxiv.org/abs/1709.01507) | [Alisher Abdulkhaev](https://twitter.com/alisher_ai) |  ![Youtube](https://www.shareicon.net/data/32x32/2016/07/09/118264_youtube_512x512.png) |
| 11/Apr/2021 | CV: Attention in GANs | [SAGAN](https://arxiv.org/abs/1805.08318) | [Mayank Bhaskar](https://twitter.com/cataluna84) | ![Youtube](https://www.shareicon.net/data/32x32/2016/07/09/118264_youtube_512x512.png) |
| 9/May/2021 | NLP: Attention | [RNN encoderâ€“decoder for SMT](https://arxiv.org/abs/1406.1078) | [Ana Valeria](https://anavaleriagonzalez.github.io/)  | ![Youtube](https://www.shareicon.net/data/32x32/2016/07/09/118264_youtube_512x512.png)  |
| 13/Jun/2021 | NLP: Attention | [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) | Charles Melby-Thompson | ![Youtube](https://www.shareicon.net/data/32x32/2016/07/09/118264_youtube_512x512.png)  |




Sessions will be held via Zoom starting at 5pm (JST) / 9am (CET). Check at what time is in your region [here](https://www.worldtimebuddy.com/japan-tokyo-to-cet).

## Format
Introduction (5min) + Paper presentation (25min) + Discussion (60min)

The introduction and paper presentation will be recorded (if agreed with the presenter) whereas the discussion will not be recorded. This format allows participants to interact during the discussion while protecting their privacy.

## For participants
As most of the time is allocated for discussion, we kindly ask participants to read the paper in advance and to join the session with at least two questions or comments in mind. These questions/comments can be to highlight interesting or unclear parts. For instance: what did you like the most about this paper? What did you learn? What did you not understand?

To make the session more interactive, participants can also ask questions during the presentation. We encourage everyone to use their microphone, but please keep in mind the environmental noise. If you cannot use your microphone or you want to keep your privacy, you are welcome to write in the Zoom chat or Slack channel, and either Jayson or Miguel will read your questions aloud.


## For presenters
Inline with the goals of MLT \_\_init\_\_, we encourage presenters to incorporate intuitive visualizations and code in Powerpoint/Slides presentations, Jupyter notebooks (+ Colab), or any other format or platform. If possible, we would like to make this material publicly available in this repository.

## Code of Conduct
As this event aims to be interactive, please remember to be kind and respectful to each other. Full code of conduct [here](https://mltokyo.ai/about).

## We want your feedback!
Feedback and contact form: https://forms.gle/jJLWyAMjjVKL8KFRA
